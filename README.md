# Deep-Learning-Notes
Deep Learning Hand Written Notes

### This Deep Learning Playlist Covers ANN,CNN and RNN 

#### **Deep Learning Playlist** (Krish Naik sir):- https://www.youtube.com/watch?v=YFNKnUhm_-s&list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi

<!------------------------------------------------->
### All about DeepLearning
Deep Learning is a subfield of machine learning concerned with algorithms inspired by the structure and function of the brain called artificial neural networks.


• The main difference between deep learning and machine learning is due to the way data is
presented in the system. Machine learning algorithms almost always require structured data, while deep learning networks rely on layers of ANN (artificial neural networks).

• Machine learning algorithms are designed to “learn” to act by understanding labeled data and then use it to produce new results with more datasets. However, when the result is incorrect, there is a need to “teach them”. Because machine learning algorithmsrequire bulleted data, they are not suitable for solving complex queries that involve a huge amount of data.

• Deep learning networks do not require human intervention, as multilevel layers in neural
networks place data in a hierarchy of different concepts, which ultimately learn from their own
mistakes. However, even they can be wrong if the data quality is not good enough.

• Data decides everything. It is the quality of the data that ultimately determines the quality of the result.

• Both of these subsets of AI are somehow connected to data, which makes it possible to represent a certain form of “intelligence.” However, you should be aware that deep learning requires much more data than a traditional machine learning algorithm. The reason for thisis that deep learning networks can identify different elements in neural network layers only when more than a million
data points interact. Machine learning algorithms, on the other hand, are capable of learning by pre-programmed criteria.

![image](https://user-images.githubusercontent.com/69152112/221349174-e0dfa45c-b6fb-45d5-8987-4589f51362a1.png)


## ANN

##### 1. Basics of ANN
##### 2. How Neural Network Works (Neural Network with Backpropagation)
##### 3. Multi layer Neural Network
##### 4. Chain Rule in Backpropagation
##### 5. Vanishing Gradient Problem
##### 6. Exploding Gradient Problem
##### 7. Drop Out & Regularization

#### Weights Initialization Techniques in NN
#### Global Minima and Local Minima

### Activation Functions:-
##### (i) Sigmoid 
##### (ii) Tanh 
##### (iii) Relu
##### (iv) Leaky Relu
##### (v) ELU
##### (vi) PRelu
##### (vii) Swish
##### (viii) Softplus
##### (ix) Softmax

### Optimizers

##### 1. Gradient Descent
##### 2. Stochastic Gradient Descent (Stochastic Gradient Descent with Momentum)
##### 3. Mini-Batch Stochastic Gradient Descient
##### 4. Adagrad  
##### 5. Adadelta and RMSprop
##### 6. Adam

#### Loss Functions

<!------------------------------------------------->

## CNN

##### 1. All about Convolution
##### 2. Padding
##### 3. Max Polling (Type of Polling)
##### 4. Operation of CNN
##### 5. Data Augmentation


<!----------------------------------------------->

## RNN

##### 1. RNN
##### 2. LSTM
##### 3. Word Embedding (Word2Vec)
##### 4. Word Embedding (Feature Representation)
##### 5. Bidirectional RNN
##### 6. Sequence To Sequence (Encoder and Decoder)
##### 7. Attention Model




